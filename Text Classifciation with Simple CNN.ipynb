{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-20T13:37:14.660911Z",
     "start_time": "2024-09-20T13:37:14.641520Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import ast\n",
    "import optuna"
   ],
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T11:12:05.555917Z",
     "start_time": "2024-09-20T11:12:05.553873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ],
   "id": "501ab40700007e06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/iangosling/PycharmProjects/Imp ML Course/.venv/bin/python\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T11:12:05.563636Z",
     "start_time": "2024-09-20T11:12:05.561400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ensuring \n",
    "print(tf.__version__)"
   ],
   "id": "ef908e4aeb21fa4c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.2\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Most of this code comes from Googles Training course on text classification:  https://developers.google.com/machine-learning/guides/text-classification.  This has been adapted and improved to include k-folds cross validation to produce a more consistent result in training.  Given the volume of training data is low.",
   "id": "e154e6a10cc0a733"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 1 - Import Train and Test Data and convert to required data type",
   "id": "d68819a701c9ab8e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T15:05:57.199655Z",
     "start_time": "2024-09-20T15:05:56.833978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load training set from CSV, convert CSV text to list and join into a single string\n",
    "train_data = pd.read_csv(\"train_data.csv\")\n",
    "train_data['preprocessed_text'] = train_data['preprocessed_text'].apply(ast.literal_eval)\n",
    "train_data['preprocessed_text'] = train_data['preprocessed_text'].apply(' '.join)\n",
    "train_texts = train_data['preprocessed_text'].to_numpy()\n",
    "\n",
    "# Load test set from CSV, convert CSV text to list and join into a single string\n",
    "test_data = pd.read_csv(\"test_data.csv\")\n",
    "test_data['preprocessed_text'] = test_data['preprocessed_text'].apply(ast.literal_eval)\n",
    "test_data['preprocessed_text'] = test_data['preprocessed_text'].apply(' '.join)\n",
    "test_texts = test_data['preprocessed_text'].to_numpy()\n"
   ],
   "id": "e9682e5da79e13db",
   "outputs": [],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T15:37:21.717641Z",
     "start_time": "2024-09-20T15:37:21.700514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create dictionary of integer values for the labels so we can convert back at a later dat\n",
    "def create_label_dict(df, col_name):\n",
    "    unique_values = df[col_name].unique()\n",
    "    value_dict = {value: i for i, value in enumerate(unique_values)}\n",
    "    return value_dict\n",
    "\n",
    "label_dict = create_label_dict(train_data, 'clause_type')\n",
    "\n",
    "# convert existing text labels to integers 1-10 using dictionary\n",
    "def transform_column(df, col_name, mapping_dict):\n",
    "    return df[col_name].map(mapping_dict).values.astype(np.float32)\n",
    "\n",
    "train_labels = transform_column(train_data, 'clause_type', label_dict)\n",
    "test_labels = transform_column(test_data, 'clause_type', label_dict)\n"
   ],
   "id": "831822be6e905b3c",
   "outputs": [],
   "execution_count": 166
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 2 - Function for Vectorisation",
   "id": "6f2269a67ee43193"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:50:16.187956Z",
     "start_time": "2024-09-20T14:50:16.177550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Vectorization parameters\n",
    "# Range (inclusive) of n-gram sizes for tokenizing text.\n",
    "NGRAM_RANGE = (1, 2)\n",
    "# Limit on the number of features. We use the top 20K features.\n",
    "TOP_K = 20000\n",
    "# Whether text should be split into word or character n-grams. One of 'word', 'char'.\n",
    "TOKEN_MODE = 'word'\n",
    "# Minimum document/corpus frequency below which a token will be discarded.\n",
    "MIN_DOCUMENT_FREQUENCY = 2\n",
    "\n",
    "def ngram_vectorize(x_train_fold, y_train_fold, x_val_fold):\n",
    "    \"\"\"Vectorizes texts as n-gram vectors.\n",
    "\n",
    "    1 text = 1 tf-idf vector the length of vocabulary of unigrams + bigrams.\n",
    "\n",
    "    # Arguments\n",
    "        x_train_fold: list, training text strings.\n",
    "        y_train_fold: np.ndarray, training labels (integers).\n",
    "        x_val_fold: list, validation text strings.\n",
    "\n",
    "    # Returns\n",
    "        x_train: vectorized training texts\n",
    "        x_val: vectorized validation texts\n",
    "    \"\"\"\n",
    "    # Create keyword arguments to pass to the 'tf-idf' vectorizer.\n",
    "    kwargs = {\n",
    "        'ngram_range': NGRAM_RANGE,  # Use 1-grams + 2-grams.\n",
    "        'dtype': 'int32',\n",
    "        'strip_accents': 'unicode',\n",
    "        'decode_error': 'replace',\n",
    "        'analyzer': TOKEN_MODE,  # Split text into word tokens.\n",
    "        'min_df': MIN_DOCUMENT_FREQUENCY,\n",
    "    }\n",
    "    vectorizer = TfidfVectorizer(**kwargs)\n",
    "\n",
    "    # Learn vocabulary from training texts and vectorize training texts.\n",
    "    x_train_fold = vectorizer.fit_transform(x_train_fold).astype(np.float32)  # Fixed variable name\n",
    "\n",
    "    # Vectorize validation texts.\n",
    "    x_val_fold = vectorizer.transform(x_val_fold).astype(np.float32)\n",
    "\n",
    "    # Select top 'k' of the vectorized features.\n",
    "    selector = SelectKBest(f_classif, k=min(TOP_K, x_train_fold.shape[1]))\n",
    "    selector.fit(x_train_fold, y_train_fold)\n",
    "    x_train = selector.transform(x_train_fold).astype('float32')\n",
    "    x_val = selector.transform(x_val_fold).astype('float32')\n",
    "\n",
    "    # Return both the vectorized texts and the original labels (y_train and y_val).\n",
    "    return x_train, x_val"
   ],
   "id": "c87db60adab68992",
   "outputs": [],
   "execution_count": 126
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 3 - Define Function to create last layer according to data parameters",
   "id": "ba754b00a763e7ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T11:12:05.927895Z",
     "start_time": "2024-09-20T11:12:05.925666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _get_last_layer_units_and_activation(num_classes):\n",
    "    \"\"\"Gets the # units and activation function for the last network layer.\n",
    "    # Arguments\n",
    "        num_classes: int, number of classes.\n",
    "    # Returns\n",
    "        units, activation values.\n",
    "    \"\"\"\n",
    "    if num_classes == 2:\n",
    "        activation = 'sigmoid'\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = 'softmax'\n",
    "        units = num_classes\n",
    "    return units, activation"
   ],
   "id": "fb8ad1b9131b9f48",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 4 - Define function to build simple multi-layer perceptron  ",
   "id": "ed7765d66908b863"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T15:36:19.469149Z",
     "start_time": "2024-09-20T15:36:19.455463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mlp_model(layers, units, dropout_rate, input_shape, num_classes):\n",
    "    \"\"\"Creates an instance of a multi-layer perceptron model.\n",
    "\n",
    "    # Arguments\n",
    "        layers: int, number of `Dense` layers in the model.\n",
    "        units: int, output dimension of the layers.\n",
    "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
    "        input_shape: tuple, shape of input to the model.\n",
    "        num_classes: int, number of output classes.\n",
    "\n",
    "    # Returns\n",
    "        An MLP model instance.\n",
    "    \"\"\"\n",
    "    op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
    "    model = models.Sequential()\n",
    "    model.add(Dropout(rate=dropout_rate, input_shape=input_shape))\n",
    "\n",
    "    for _ in range(layers-1):\n",
    "        model.add(Dense(units=units, activation='relu'))\n",
    "        model.add(Dropout(rate=dropout_rate))\n",
    "\n",
    "    model.add(Dense(units=op_units, activation=op_activation))\n",
    "    \n",
    "    return model"
   ],
   "id": "df68b7eeb4ef9a6e",
   "outputs": [],
   "execution_count": 165
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 5 - Create a function to train the n_gram model",
   "id": "36ea8c1fa496035b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T15:35:02.247638Z",
     "start_time": "2024-09-20T15:35:02.235932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train model with kfolds validation\n",
    "def train_ngram_model_kfolds(data,k=5,\n",
    "                      learning_rate=1e-3,\n",
    "                      epochs=1000,\n",
    "                      batch_size=128,\n",
    "                      layers=2,\n",
    "                      units=64,\n",
    "                      dropout_rate=0.2,\n",
    "                      num_classes=10):\n",
    "\n",
    "    \"\"\"Trains n-gram model on the given dataset.\n",
    "\n",
    "    # Arguments\n",
    "        k: no of folds \n",
    "        data: tuples of training and test texts and labels.\n",
    "        learning_rate: float, learning rate for training model.\n",
    "        epochs: int, number of epochs.\n",
    "        batch_size: int, number of samples per batch.\n",
    "        layers: int, number of `Dense` layers in the model.\n",
    "        units: int, output dimension of Dense layers in the model.\n",
    "        dropout_rate: float: percentage of input to drop at Dropout layers.\n",
    "        num_classes: int, number of output classes.\n",
    "    \"\"\"\n",
    "    # Get the data.\n",
    "    train_texts, train_labels = data\n",
    "    \n",
    "    # Prepare k-fold cross-validation\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Store validation results for each fold\n",
    "    val_accuracies = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Perform K-Fold Cross-Validation\n",
    "    for train_idx, val_idx in kfold.split(train_texts):\n",
    "        # Split data into training and validation for this fold\n",
    "        # K-fold cross-validation\n",
    "        x_train_fold = train_texts[train_idx]\n",
    "        y_train_fold = train_labels[train_idx]\n",
    "        x_val_fold = train_texts[val_idx]\n",
    "        y_val_fold = train_labels[val_idx]\n",
    "        \n",
    "        # Vectorize texts.\n",
    "        x_train, x_val = ngram_vectorize(x_train_fold, y_train_fold, x_val_fold) \n",
    "        # Create model instance.\n",
    "        model = mlp_model(layers=layers,\n",
    "                          units=units,\n",
    "                          dropout_rate=dropout_rate,\n",
    "                          input_shape=x_train.shape[1:],\n",
    "                          num_classes=num_classes)\n",
    "        \n",
    "        loss = 'sparse_categorical_crossentropy'\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "    \n",
    "        # Create callback for early stopping on validation loss. If the loss does not decrease in two consecutive tries, stop training.\n",
    "        callbacks = [EarlyStopping(monitor='val_loss', patience=2)]\n",
    "        \n",
    "        # Train and validate the model on this fold\n",
    "        history = model.fit(\n",
    "            x_train,\n",
    "            y_train_fold,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            validation_data=(x_val, y_val_fold),\n",
    "            verbose=2,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "        # Collect the last validation accuracy and loss\n",
    "        history = history.history\n",
    "        val_accuracies.append(history['val_accuracy'][-1])\n",
    "        val_losses.append(history['val_loss'][-1])\n",
    "    \n",
    "    # Compute average validation accuracy and loss\n",
    "    avg_val_accuracy = np.mean(val_accuracies)\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    \n",
    "    # Print results.\n",
    "    print('Average Validation Accuracy: {:.4f}, Average Loss: {:.4f}'.format(avg_val_accuracy, avg_val_loss))\n",
    "\n",
    "    # Save model.\n",
    "    model.save('Clause_class_model.keras')\n",
    "    \n",
    "    return avg_val_accuracy, avg_val_loss"
   ],
   "id": "abd70653b3f68254",
   "outputs": [],
   "execution_count": 163
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9cddc006b14ab535"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 6 - Build Model and train model",
   "id": "51a79aca1c33a7e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T15:35:44.447518Z",
     "start_time": "2024-09-20T15:35:22.006259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = (train_texts, train_labels)\n",
    "train_ngram_model_kfolds(data)"
   ],
   "id": "9cd6af2e41d3676f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iangosling/PycharmProjects/Imp ML Course/.venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:2030: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 softmax\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iangosling/PycharmProjects/Imp ML Course/.venv/lib/python3.9/site-packages/keras/src/layers/regularization/dropout.py:42: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 - 0s - 43ms/step - accuracy: 0.5834 - loss: 2.2311 - val_accuracy: 0.7988 - val_loss: 2.0974\n",
      "Epoch 2/1000\n",
      "11/11 - 0s - 10ms/step - accuracy: 0.8728 - loss: 1.9840 - val_accuracy: 0.8142 - val_loss: 1.8538\n",
      "Epoch 3/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.8999 - loss: 1.7105 - val_accuracy: 0.8359 - val_loss: 1.6045\n",
      "Epoch 4/1000\n",
      "11/11 - 0s - 10ms/step - accuracy: 0.9209 - loss: 1.4495 - val_accuracy: 0.8452 - val_loss: 1.3685\n",
      "Epoch 5/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9255 - loss: 1.2014 - val_accuracy: 0.8576 - val_loss: 1.1532\n",
      "Epoch 6/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9325 - loss: 0.9936 - val_accuracy: 0.8576 - val_loss: 0.9798\n",
      "Epoch 7/1000\n",
      "11/11 - 0s - 10ms/step - accuracy: 0.9325 - loss: 0.8166 - val_accuracy: 0.8545 - val_loss: 0.8440\n",
      "Epoch 8/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9426 - loss: 0.6811 - val_accuracy: 0.8545 - val_loss: 0.7399\n",
      "Epoch 9/1000\n",
      "11/11 - 0s - 10ms/step - accuracy: 0.9403 - loss: 0.5774 - val_accuracy: 0.8576 - val_loss: 0.6649\n",
      "Epoch 10/1000\n",
      "11/11 - 0s - 10ms/step - accuracy: 0.9488 - loss: 0.4846 - val_accuracy: 0.8607 - val_loss: 0.6082\n",
      "Epoch 11/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9542 - loss: 0.4339 - val_accuracy: 0.8607 - val_loss: 0.5662\n",
      "Epoch 12/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9542 - loss: 0.3805 - val_accuracy: 0.8638 - val_loss: 0.5351\n",
      "Epoch 13/1000\n",
      "11/11 - 0s - 10ms/step - accuracy: 0.9635 - loss: 0.3340 - val_accuracy: 0.8638 - val_loss: 0.5098\n",
      "Epoch 14/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9635 - loss: 0.2972 - val_accuracy: 0.8638 - val_loss: 0.4896\n",
      "Epoch 15/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9682 - loss: 0.2717 - val_accuracy: 0.8607 - val_loss: 0.4735\n",
      "Epoch 16/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9690 - loss: 0.2497 - val_accuracy: 0.8638 - val_loss: 0.4611\n",
      "Epoch 17/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9713 - loss: 0.2232 - val_accuracy: 0.8638 - val_loss: 0.4500\n",
      "Epoch 18/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9752 - loss: 0.2028 - val_accuracy: 0.8607 - val_loss: 0.4414\n",
      "Epoch 19/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9705 - loss: 0.1960 - val_accuracy: 0.8638 - val_loss: 0.4344\n",
      "Epoch 20/1000\n",
      "11/11 - 0s - 10ms/step - accuracy: 0.9767 - loss: 0.1733 - val_accuracy: 0.8607 - val_loss: 0.4290\n",
      "Epoch 21/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9814 - loss: 0.1580 - val_accuracy: 0.8638 - val_loss: 0.4236\n",
      "Epoch 22/1000\n",
      "11/11 - 0s - 10ms/step - accuracy: 0.9822 - loss: 0.1502 - val_accuracy: 0.8607 - val_loss: 0.4197\n",
      "Epoch 23/1000\n",
      "11/11 - 0s - 10ms/step - accuracy: 0.9860 - loss: 0.1352 - val_accuracy: 0.8576 - val_loss: 0.4166\n",
      "Epoch 24/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9822 - loss: 0.1344 - val_accuracy: 0.8607 - val_loss: 0.4142\n",
      "Epoch 25/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9876 - loss: 0.1177 - val_accuracy: 0.8576 - val_loss: 0.4131\n",
      "Epoch 26/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9891 - loss: 0.1131 - val_accuracy: 0.8483 - val_loss: 0.4126\n",
      "Epoch 27/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9876 - loss: 0.1059 - val_accuracy: 0.8483 - val_loss: 0.4125\n",
      "Epoch 28/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9915 - loss: 0.0967 - val_accuracy: 0.8576 - val_loss: 0.4122\n",
      "Epoch 29/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9899 - loss: 0.0946 - val_accuracy: 0.8514 - val_loss: 0.4116\n",
      "Epoch 30/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9868 - loss: 0.0916 - val_accuracy: 0.8638 - val_loss: 0.4112\n",
      "Epoch 31/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9891 - loss: 0.0849 - val_accuracy: 0.8607 - val_loss: 0.4112\n",
      "Epoch 32/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9922 - loss: 0.0796 - val_accuracy: 0.8483 - val_loss: 0.4113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iangosling/PycharmProjects/Imp ML Course/.venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:2030: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 softmax\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iangosling/PycharmProjects/Imp ML Course/.venv/lib/python3.9/site-packages/keras/src/layers/regularization/dropout.py:42: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 - 0s - 41ms/step - accuracy: 0.5834 - loss: 2.2359 - val_accuracy: 0.8050 - val_loss: 2.1075\n",
      "Epoch 2/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.8852 - loss: 1.9914 - val_accuracy: 0.8452 - val_loss: 1.8624\n",
      "Epoch 3/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9092 - loss: 1.7238 - val_accuracy: 0.8514 - val_loss: 1.6111\n",
      "Epoch 4/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9154 - loss: 1.4486 - val_accuracy: 0.8669 - val_loss: 1.3679\n",
      "Epoch 5/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9209 - loss: 1.1911 - val_accuracy: 0.8607 - val_loss: 1.1527\n",
      "Epoch 6/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9317 - loss: 0.9769 - val_accuracy: 0.8607 - val_loss: 0.9779\n",
      "Epoch 7/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9333 - loss: 0.7983 - val_accuracy: 0.8700 - val_loss: 0.8444\n",
      "Epoch 8/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9379 - loss: 0.6649 - val_accuracy: 0.8793 - val_loss: 0.7422\n",
      "Epoch 9/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9496 - loss: 0.5606 - val_accuracy: 0.8885 - val_loss: 0.6648\n",
      "Epoch 10/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9503 - loss: 0.4805 - val_accuracy: 0.8885 - val_loss: 0.6077\n",
      "Epoch 11/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9465 - loss: 0.4151 - val_accuracy: 0.8854 - val_loss: 0.5646\n",
      "Epoch 12/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9620 - loss: 0.3581 - val_accuracy: 0.8916 - val_loss: 0.5279\n",
      "Epoch 13/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9666 - loss: 0.3214 - val_accuracy: 0.8916 - val_loss: 0.5007\n",
      "Epoch 14/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9643 - loss: 0.2903 - val_accuracy: 0.8916 - val_loss: 0.4812\n",
      "Epoch 15/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9690 - loss: 0.2631 - val_accuracy: 0.8885 - val_loss: 0.4647\n",
      "Epoch 16/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9752 - loss: 0.2359 - val_accuracy: 0.8854 - val_loss: 0.4485\n",
      "Epoch 17/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9798 - loss: 0.2066 - val_accuracy: 0.8824 - val_loss: 0.4370\n",
      "Epoch 18/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9806 - loss: 0.1903 - val_accuracy: 0.8793 - val_loss: 0.4264\n",
      "Epoch 19/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9798 - loss: 0.1746 - val_accuracy: 0.8824 - val_loss: 0.4168\n",
      "Epoch 20/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9814 - loss: 0.1625 - val_accuracy: 0.8854 - val_loss: 0.4119\n",
      "Epoch 21/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9845 - loss: 0.1509 - val_accuracy: 0.8824 - val_loss: 0.4032\n",
      "Epoch 22/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9868 - loss: 0.1411 - val_accuracy: 0.8793 - val_loss: 0.3975\n",
      "Epoch 23/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9884 - loss: 0.1267 - val_accuracy: 0.8793 - val_loss: 0.3950\n",
      "Epoch 24/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9907 - loss: 0.1175 - val_accuracy: 0.8824 - val_loss: 0.3904\n",
      "Epoch 25/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9915 - loss: 0.1073 - val_accuracy: 0.8762 - val_loss: 0.3898\n",
      "Epoch 26/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9907 - loss: 0.1029 - val_accuracy: 0.8762 - val_loss: 0.3896\n",
      "Epoch 27/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9876 - loss: 0.0996 - val_accuracy: 0.8762 - val_loss: 0.3864\n",
      "Epoch 28/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9907 - loss: 0.0897 - val_accuracy: 0.8762 - val_loss: 0.3840\n",
      "Epoch 29/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9938 - loss: 0.0888 - val_accuracy: 0.8762 - val_loss: 0.3841\n",
      "Epoch 30/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9961 - loss: 0.0759 - val_accuracy: 0.8731 - val_loss: 0.3806\n",
      "Epoch 31/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9953 - loss: 0.0763 - val_accuracy: 0.8762 - val_loss: 0.3787\n",
      "Epoch 32/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9915 - loss: 0.0759 - val_accuracy: 0.8731 - val_loss: 0.3779\n",
      "Epoch 33/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9938 - loss: 0.0665 - val_accuracy: 0.8762 - val_loss: 0.3778\n",
      "Epoch 34/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9938 - loss: 0.0658 - val_accuracy: 0.8762 - val_loss: 0.3756\n",
      "Epoch 35/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9930 - loss: 0.0614 - val_accuracy: 0.8731 - val_loss: 0.3726\n",
      "Epoch 36/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9961 - loss: 0.0556 - val_accuracy: 0.8731 - val_loss: 0.3734\n",
      "Epoch 37/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9953 - loss: 0.0580 - val_accuracy: 0.8731 - val_loss: 0.3733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iangosling/PycharmProjects/Imp ML Course/.venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:2030: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 softmax\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iangosling/PycharmProjects/Imp ML Course/.venv/lib/python3.9/site-packages/keras/src/layers/regularization/dropout.py:42: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 - 0s - 40ms/step - accuracy: 0.6109 - loss: 2.2347 - val_accuracy: 0.8509 - val_loss: 2.1018\n",
      "Epoch 2/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.8837 - loss: 1.9888 - val_accuracy: 0.8385 - val_loss: 1.8527\n",
      "Epoch 3/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.8899 - loss: 1.7106 - val_accuracy: 0.8447 - val_loss: 1.5967\n",
      "Epoch 4/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9078 - loss: 1.4395 - val_accuracy: 0.8540 - val_loss: 1.3518\n",
      "Epoch 5/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9155 - loss: 1.1845 - val_accuracy: 0.8571 - val_loss: 1.1367\n",
      "Epoch 6/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9295 - loss: 0.9797 - val_accuracy: 0.8602 - val_loss: 0.9599\n",
      "Epoch 7/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9380 - loss: 0.7953 - val_accuracy: 0.8665 - val_loss: 0.8232\n",
      "Epoch 8/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9426 - loss: 0.6613 - val_accuracy: 0.8602 - val_loss: 0.7209\n",
      "Epoch 9/1000\n",
      "11/11 - 0s - 14ms/step - accuracy: 0.9395 - loss: 0.5551 - val_accuracy: 0.8540 - val_loss: 0.6444\n",
      "Epoch 10/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9496 - loss: 0.4758 - val_accuracy: 0.8540 - val_loss: 0.5881\n",
      "Epoch 11/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9543 - loss: 0.4190 - val_accuracy: 0.8665 - val_loss: 0.5462\n",
      "Epoch 12/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9667 - loss: 0.3660 - val_accuracy: 0.8665 - val_loss: 0.5123\n",
      "Epoch 13/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9628 - loss: 0.3236 - val_accuracy: 0.8696 - val_loss: 0.4841\n",
      "Epoch 14/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9729 - loss: 0.2850 - val_accuracy: 0.8634 - val_loss: 0.4639\n",
      "Epoch 15/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9752 - loss: 0.2572 - val_accuracy: 0.8634 - val_loss: 0.4476\n",
      "Epoch 16/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9775 - loss: 0.2344 - val_accuracy: 0.8634 - val_loss: 0.4332\n",
      "Epoch 17/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9736 - loss: 0.2145 - val_accuracy: 0.8727 - val_loss: 0.4219\n",
      "Epoch 18/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9806 - loss: 0.1946 - val_accuracy: 0.8727 - val_loss: 0.4131\n",
      "Epoch 19/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9837 - loss: 0.1756 - val_accuracy: 0.8727 - val_loss: 0.4037\n",
      "Epoch 20/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9837 - loss: 0.1619 - val_accuracy: 0.8789 - val_loss: 0.3962\n",
      "Epoch 21/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9829 - loss: 0.1499 - val_accuracy: 0.8758 - val_loss: 0.3914\n",
      "Epoch 22/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9899 - loss: 0.1328 - val_accuracy: 0.8758 - val_loss: 0.3881\n",
      "Epoch 23/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9868 - loss: 0.1271 - val_accuracy: 0.8758 - val_loss: 0.3855\n",
      "Epoch 24/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9876 - loss: 0.1186 - val_accuracy: 0.8758 - val_loss: 0.3818\n",
      "Epoch 25/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9907 - loss: 0.1073 - val_accuracy: 0.8727 - val_loss: 0.3816\n",
      "Epoch 26/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9899 - loss: 0.1008 - val_accuracy: 0.8727 - val_loss: 0.3798\n",
      "Epoch 27/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9938 - loss: 0.0937 - val_accuracy: 0.8696 - val_loss: 0.3754\n",
      "Epoch 28/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9907 - loss: 0.0910 - val_accuracy: 0.8665 - val_loss: 0.3738\n",
      "Epoch 29/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9915 - loss: 0.0889 - val_accuracy: 0.8665 - val_loss: 0.3743\n",
      "Epoch 30/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9946 - loss: 0.0776 - val_accuracy: 0.8665 - val_loss: 0.3734\n",
      "Epoch 31/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9953 - loss: 0.0720 - val_accuracy: 0.8665 - val_loss: 0.3718\n",
      "Epoch 32/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9938 - loss: 0.0711 - val_accuracy: 0.8696 - val_loss: 0.3720\n",
      "Epoch 33/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9953 - loss: 0.0646 - val_accuracy: 0.8727 - val_loss: 0.3731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iangosling/PycharmProjects/Imp ML Course/.venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:2030: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 softmax\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iangosling/PycharmProjects/Imp ML Course/.venv/lib/python3.9/site-packages/keras/src/layers/regularization/dropout.py:42: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 - 0s - 40ms/step - accuracy: 0.6209 - loss: 2.2340 - val_accuracy: 0.7919 - val_loss: 2.1110\n",
      "Epoch 2/1000\n",
      "11/11 - 0s - 10ms/step - accuracy: 0.8837 - loss: 1.9865 - val_accuracy: 0.7950 - val_loss: 1.8772\n",
      "Epoch 3/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.8860 - loss: 1.7176 - val_accuracy: 0.7919 - val_loss: 1.6387\n",
      "Epoch 4/1000\n",
      "11/11 - 0s - 10ms/step - accuracy: 0.9163 - loss: 1.4465 - val_accuracy: 0.7857 - val_loss: 1.4083\n",
      "Epoch 5/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9248 - loss: 1.1947 - val_accuracy: 0.7981 - val_loss: 1.2067\n",
      "Epoch 6/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9256 - loss: 0.9833 - val_accuracy: 0.8199 - val_loss: 1.0415\n",
      "Epoch 7/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9341 - loss: 0.8084 - val_accuracy: 0.8354 - val_loss: 0.9117\n",
      "Epoch 8/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9457 - loss: 0.6776 - val_accuracy: 0.8447 - val_loss: 0.8120\n",
      "Epoch 9/1000\n",
      "11/11 - 0s - 10ms/step - accuracy: 0.9388 - loss: 0.5716 - val_accuracy: 0.8447 - val_loss: 0.7351\n",
      "Epoch 10/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9535 - loss: 0.4829 - val_accuracy: 0.8447 - val_loss: 0.6732\n",
      "Epoch 11/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9581 - loss: 0.4179 - val_accuracy: 0.8509 - val_loss: 0.6244\n",
      "Epoch 12/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9636 - loss: 0.3700 - val_accuracy: 0.8478 - val_loss: 0.5881\n",
      "Epoch 13/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9605 - loss: 0.3251 - val_accuracy: 0.8509 - val_loss: 0.5590\n",
      "Epoch 14/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9674 - loss: 0.2880 - val_accuracy: 0.8478 - val_loss: 0.5394\n",
      "Epoch 15/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9775 - loss: 0.2490 - val_accuracy: 0.8478 - val_loss: 0.5226\n",
      "Epoch 16/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9775 - loss: 0.2286 - val_accuracy: 0.8478 - val_loss: 0.5078\n",
      "Epoch 17/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9775 - loss: 0.2082 - val_accuracy: 0.8478 - val_loss: 0.4968\n",
      "Epoch 18/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9783 - loss: 0.1908 - val_accuracy: 0.8478 - val_loss: 0.4883\n",
      "Epoch 19/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9853 - loss: 0.1655 - val_accuracy: 0.8478 - val_loss: 0.4843\n",
      "Epoch 20/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9884 - loss: 0.1580 - val_accuracy: 0.8447 - val_loss: 0.4785\n",
      "Epoch 21/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9845 - loss: 0.1440 - val_accuracy: 0.8385 - val_loss: 0.4836\n",
      "Epoch 22/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9845 - loss: 0.1339 - val_accuracy: 0.8385 - val_loss: 0.4787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iangosling/PycharmProjects/Imp ML Course/.venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:2030: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 softmax\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iangosling/PycharmProjects/Imp ML Course/.venv/lib/python3.9/site-packages/keras/src/layers/regularization/dropout.py:42: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 - 0s - 40ms/step - accuracy: 0.5783 - loss: 2.2374 - val_accuracy: 0.8540 - val_loss: 2.1051\n",
      "Epoch 2/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.8581 - loss: 1.9997 - val_accuracy: 0.8634 - val_loss: 1.8628\n",
      "Epoch 3/1000\n",
      "11/11 - 0s - 10ms/step - accuracy: 0.8845 - loss: 1.7361 - val_accuracy: 0.8571 - val_loss: 1.6166\n",
      "Epoch 4/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9093 - loss: 1.4781 - val_accuracy: 0.8634 - val_loss: 1.3798\n",
      "Epoch 5/1000\n",
      "11/11 - 0s - 10ms/step - accuracy: 0.9240 - loss: 1.2275 - val_accuracy: 0.8665 - val_loss: 1.1716\n",
      "Epoch 6/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9240 - loss: 1.0187 - val_accuracy: 0.8727 - val_loss: 0.9968\n",
      "Epoch 7/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9341 - loss: 0.8452 - val_accuracy: 0.8696 - val_loss: 0.8577\n",
      "Epoch 8/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9395 - loss: 0.7119 - val_accuracy: 0.8789 - val_loss: 0.7529\n",
      "Epoch 9/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9411 - loss: 0.5999 - val_accuracy: 0.8727 - val_loss: 0.6684\n",
      "Epoch 10/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9574 - loss: 0.5118 - val_accuracy: 0.8913 - val_loss: 0.6040\n",
      "Epoch 11/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9519 - loss: 0.4480 - val_accuracy: 0.8913 - val_loss: 0.5558\n",
      "Epoch 12/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9558 - loss: 0.3827 - val_accuracy: 0.8975 - val_loss: 0.5174\n",
      "Epoch 13/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9628 - loss: 0.3461 - val_accuracy: 0.9037 - val_loss: 0.4837\n",
      "Epoch 14/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9651 - loss: 0.3047 - val_accuracy: 0.8944 - val_loss: 0.4651\n",
      "Epoch 15/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9729 - loss: 0.2693 - val_accuracy: 0.8944 - val_loss: 0.4462\n",
      "Epoch 16/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9767 - loss: 0.2448 - val_accuracy: 0.8944 - val_loss: 0.4282\n",
      "Epoch 17/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9760 - loss: 0.2177 - val_accuracy: 0.8882 - val_loss: 0.4129\n",
      "Epoch 18/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9783 - loss: 0.2009 - val_accuracy: 0.8975 - val_loss: 0.4020\n",
      "Epoch 19/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9767 - loss: 0.1870 - val_accuracy: 0.8975 - val_loss: 0.3950\n",
      "Epoch 20/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9829 - loss: 0.1705 - val_accuracy: 0.8975 - val_loss: 0.3894\n",
      "Epoch 21/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9806 - loss: 0.1589 - val_accuracy: 0.8975 - val_loss: 0.3813\n",
      "Epoch 22/1000\n",
      "11/11 - 0s - 12ms/step - accuracy: 0.9860 - loss: 0.1463 - val_accuracy: 0.8975 - val_loss: 0.3765\n",
      "Epoch 23/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9899 - loss: 0.1314 - val_accuracy: 0.8975 - val_loss: 0.3705\n",
      "Epoch 24/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9891 - loss: 0.1234 - val_accuracy: 0.9006 - val_loss: 0.3652\n",
      "Epoch 25/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9915 - loss: 0.1094 - val_accuracy: 0.8944 - val_loss: 0.3644\n",
      "Epoch 26/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9915 - loss: 0.1070 - val_accuracy: 0.9006 - val_loss: 0.3638\n",
      "Epoch 27/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9922 - loss: 0.0968 - val_accuracy: 0.8913 - val_loss: 0.3635\n",
      "Epoch 28/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9961 - loss: 0.0897 - val_accuracy: 0.8913 - val_loss: 0.3613\n",
      "Epoch 29/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9922 - loss: 0.0828 - val_accuracy: 0.8882 - val_loss: 0.3598\n",
      "Epoch 30/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9953 - loss: 0.0775 - val_accuracy: 0.8882 - val_loss: 0.3573\n",
      "Epoch 31/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9946 - loss: 0.0766 - val_accuracy: 0.8913 - val_loss: 0.3536\n",
      "Epoch 32/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9953 - loss: 0.0717 - val_accuracy: 0.8913 - val_loss: 0.3548\n",
      "Epoch 33/1000\n",
      "11/11 - 0s - 11ms/step - accuracy: 0.9961 - loss: 0.0644 - val_accuracy: 0.8944 - val_loss: 0.3548\n",
      "Average Validation Accuracy: 0.8654, Average Loss: 0.3982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8653904676437378, 0.39823356866836546)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 164
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5d52ae0eb52a0a4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8e83184e15dc425f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "faf2a6d13f61feca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 8 - Tune Hyperparameters",
   "id": "bc2e6b6ffef036ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "47dbf769c906ace2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ece1420b3640de4f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 10 - Test Model\n",
   "id": "6971e517bc25e782"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1a44ea0e700efa0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
